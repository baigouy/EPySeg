# HQ predictions

**HQ predictions** is just a **hack that aims at getting better a segmentation/prediction for the given input images**. Practically, the software will pass the same image (with horizontal and vertical flip, various intensity corrections and various rotations that do not require interpolation, i.e. rotations by multiples of 90 degrees) up to 12 times to the model and compute the max or average output from those 12 passes to get back to a single prediction in the end. The fact that when the same image is passed to the model with or without a 90 degrees rotation, it does not produce the same output is most likely a hint that **there are biases in the input dataset used for training**. A known bias is for example that most images used for training are oriented in the same direction (proximal to the right and distal to the left), therefore this most likely makes the model less prone to detect cells in other orientations, this is partially fixed thanks to data augmentation but not completely and biases still persist. The combination of the augmented 12 outputs attenuates training biases and thereby further improves segmentation quality.